---
title: "Homework 1"
author: "42205 / Marc Gehring"
date: "2022-02-14"
output:
  pdf_document: 
    fig_height: 3
  html_notebook: default
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[C]{Applied Financial Econometrics}
- \fancyfoot[C]{\thepage}
---

# 1.

```{r setup, message = FALSE}
library(tidyverse)
library(readxl)
library(lubridate)
library(reshape2)
library(psych)
library(ggh4x)
library(QRM)
library(moments)
library(stats)
library(MASS)
```

## (a)
```{r, message = FALSE}
path = paste0(getwd(), "/data_assignment1.xlsx")
data = lapply(excel_sheets(path), read_excel, path = path)

data = data[[1]]
data = data %>% mutate(DATE = ymd(DATE))
data = data.frame(data[,1], sapply(data[,(2:6)], unlist))

head(data)
```

## (b)
```{r, message = FALSE}
simpleToLog = function(returns) {return(log(returns + 1))}
for (i in (2:ncol(data))) {
  data[paste0("log",names(data)[i])] = simpleToLog(data[, i])
}

head(data)
```

## (c)
```{r, message = FALSE}
ggplot(melt(data[,1:6], id.vars = "DATE"), aes(DATE, value, color = variable)) + 
geom_line() + 
ggtitle("Simple Returns 1963-2011") + 
labs(x = "Date", y = "Simple return") + 
guides(color = guide_legend(title = "Stocks")) + 
theme_classic()

ggplot(melt(data[,c(1,7:ncol(data))], id.vars = "DATE"), 
  aes(DATE, value, color = variable)) + 
geom_line() + 
ggtitle("Log Returns 1963-2011") + 
labs(x = "Date", y = "Log return") + 
guides(color = guide_legend(title = "Stocks")) + 
theme_classic()
```

There are no striking differences between the patterns of the simple and the log returns. That comes as no surprise, as simple and log returns are similar for small numbers. Individual time series are hard to distinguish. One can, however, see periods of higher volatility and peaking returns. At the beginning of the 2000s, for example, you can see a relatively broad range of spikes, corresponding to the dot-com bubble. Similarly, you can see large negative spikes around the time of the global financial crisis. In general, the individual stocks, compared to the stock indices, peak more extremely, more often. The inner band of the data seems to be dominated by the colors of the two stock indices. This is to be expected, as a consequence of diversification within a stock index.

## (d)
``` {r, message = FALSE}
ggplot(melt(data[,c(1,7:ncol(data))], id.vars = "DATE"), 
  aes(DATE, value, color = variable)) + 
geom_point() +
ggtitle("Log Returns 1963-2011") + 
labs(x = "Date", y = "Log return") + 
guides(color = guide_legend(title = "Stocks")) + 
theme_classic()
```

This plot is similar in content to the previous one. In this plot, though, it perhaps becomes more apparent that on the whole, the returns of the indices tend to be closer to 0. The data points of COCACOLA, GE, and IBM tend to lie outside of the cloud of index data points.

## (e)
``` {r, message = FALSE}
descriptiveStats = describe(data[, 7:ncol(data)]) %>% 
  mutate(excessKurtosis = kurtosis - 3)
descriptiveStats
```

The equally-weighted index has a higher average return than the value-weighted index; 0.0101 vs 0.0077. At the same time, the equally-weighted index is more volatile, as measured by variance, than the value-weighted index; 0.0033 vs 0.0021. Both return series are negatively skewed, indicating that the tail is on the left side of the distribution. The value-weighted index exhibits more skewness than the equally-weighted index; -0.7994 vs -0.6136. Excess kurtosis describes the shape of the distribution tails. The normal distribution has kurtosis of 3, so the kurtosis value of a distribution minus 3 is the excess kurtosis. The value-weighted index has negative excess kurtosis of -0.1418, making it platykurtic; the distribution's tails are thinner than those of a normal distribution. Extreme events occur less frequently than predicted by a normal distribution. The equally-weighted index has positive excess kurtosis of 0.4465, making it leptokurtic; the distribution's tails are thicker than those of a normal distribution. Extreme events occur more frequently than predicted by a normal distribution. Finally, the value-weighted index has a broader range of returns, from -0.2554 to +0.1532. The returns of the equally-weighted index, on the other hand, range from -0.3178 to +0.2618. This seems to agree with the excess kurtosis values.

## (f)
``` {r, message = FALSE}
for (i in 7:ncol(data)) {
  print(names(data)[i])
  print(t.test(data[, i], mu = 0))
  print(agostino.test(data[[i]]))
  print(anscombe.test(data[[i]]))
}
```

For all log series, the mean is statistically significant from 0 at the 5% significance level. Whether the skewness is statistically significantly different from 0 and the kurtosis from 3, can be tested with the D'Agostino skewness test and the Anscombe-Glynn kurtosis test, respectively. For COCACOLA and GE, we can reject the null hypotheses of no skewness and no excess kurtosis at the 1% significance level. For IBM, we can reject the hypothesis of no skewness at the 10% significance level and the hypothesis of no excess kurtosis at the 1% significance level. Apparently, the returns of logIBM are less skewed. For both stock indices, we can reject the hypotheses of no skewness and no excess kurtosis at the 1% significance level. So, overall, the return series are skewed and show excess kurtosis, indicating non-normal distributions. This also confirms the observations made in the previous item.

## (g)
``` {r, message = FALSE}
for(i in 7:ncol(data)) {
  x = (data[,i] - mean(data[,i], rm.na = TRUE))/sd(data[,i]) 
  par(mar=c(4, 4,1,1), mfrow=c(1,1), xpd=F, new=FALSE)
  
  h = hist(x, breaks = 100, col = "gray", xlab = "Log return", main = paste(colnames(data[i]), 
    " (Normalized)"))
  
  xfit = seq(min(x), max(x), length = 80)
  nfit = dnorm(xfit, mean = mean(x), sd = sd(x))
  nfit = nfit * diff(h$mids[1:2]) * length(x)
  lines(xfit, nfit, col = "blue", lwd = 2)
  
  mod  = fitdistr(x, densfun = "t")
  tfit = dt(xfit, mod$estimate[3])
  tfit = tfit*diff(h$mids[1:2]) * length(x)
  lines(xfit, tfit, col = "red", lwd = 2)
  
  legend("topleft", col=c("blue", "red"), legend=c("Normal", paste("t (", round(mod$estimate[3], digits=1),
    " df)", sep="")), pch=20)
  
  print(shapiro.test(data[,i]))
}
```

At first glance, the histograms of the different actual and fitted distributions look mostly normal, in that they are unimodal and to a degree "peaky". One can see that for every return series, the t-distribution is more peaky around the mean and dips below the normal distribution at around 0.5 SDs. Though not quite discernible, the t-distribution is expected to have fatter tails than the normal distribution. The outliers, however, likely render the distributions non-normal. One can also see a negative skew in every distribution. This can also be seen at the intersections at the 0.5 SD vertical lines. In terms of kurtosis, the distributions exhibit extreme data points at the tail ends, where we would not expect such values according to a normal distribution. The t-distribution is more appropriate in this regard.
When one increases the number of bins to 100, it becomes apparent that the t-distribution does a better job at describing the data than the normal distribution. Comparing the log stock returns to the log index returns, the index returns look closer to the t-distribution than the stock returns.
In the Jarque-Bera-test, the null hypothesis is a joint hypothesis of the skewness being 0 and the excess kurtosis being 0. If the statistic is far from 0, it signals the data do not resemble a normal distribution. For every return series, the JB statistic is very large and we can reject the null hypothesis at the 1% significance level in each case. This means that the skewness and kurtosis values are (combined) non-normal for each distribution.

## (h)
```{r}
for (i in (2:4)) {
  print(names(data)[i])
  lm = lm(data[[i]] ~ VWRET, data)
  print(summary(lm))
}

for (i in (7:9)) {
  print(names(data)[i])
  lm = lm(data[[i]] ~ logVWRET, data)
  print(summary(lm))
}
```

I decided to run the regression on the value-weighted index, since value-weighted indices tend to reflect better the actual value allocation in a portfolio than equally-weighted indices. For GE and IBM, we fail to reject the null hypothesis that the alpha is 0 at the 10% significance level. The values are 0.0005 and 0.0028, respectively. For COCACOLA, we find that alpha, 0.0065, is statistically significantly different from 0 at the 1% significance level. This information could be useful in an investment decision or in setting up an investment strategy. COCACOLA's beta is 0.7164, GE's is 1.1200, and IBM's is 0.8797. All are statistically significantly different from 0 at the 1% significance level. Accordingly, GE can be considered a cyclical stock and both COCACOLA and IBM counter-cyclical stocks.
A similar pictures emerges from the log returns, though the coefficients and standard errors change slightly and the alpha of logCOCACOLA is now statistically significant at the 5% significance level, but no longer at the 1% significance level.


# 2.
```{r, message = FALSE}
library(haven)
library(car)
library(lmtest)
library(sandwich)
```

## (a)
```{r, message = FALSE}
path = paste0(getwd(), "/pension.dta")
data = read_dta(path)
data[c("e401k", "marr", "male", "p401k", "pira")] = 
lapply(data[c("e401k", "marr", "male", "p401k", "pira")], as.factor)

head(data)
```

## (b)
```{r, message = FALSE}
paste0("There are ", toString(sum(data$fsize == 1)), 
  " single households. This is equivalent of ", 
  toString(round(sum(data$fsize == 1)/nrow(data)*100)), "% of the sample.")
```

## (c) & (d)
```{r, message = FALSE}
dataLM = data %>% dplyr::filter(fsize == 1) 
lm = lm(nettfa ~ inc + age, dataLM)
summary(lm)
```

For single-person households, the net financial wealth increases positively with both (family) income (beta of  0.7993) and age (beta of 0.8427). The intercept of -43.0398, on average, is perhaps nonsensical, though, since negative net financial wealth at age 0 and income 0 does not make much sense (unless the individual inherits a considerable amount of financial debt). This calls into question the external validity of this regression model for low age and/or low income individuals living on their own. 
Nonetheless, an individual of a single-person household is expected to increase her/his financial wealth by 799 USD for every additional 1,000 USD income, on average, certeris paribus. Similarly, individuals that are 1 year older are expected to have financial wealth greater by 842 USD, on average, certeris paribus. The intercept and the coefficients are statistically significant at the 1% significance level.

## (e)
```{r, message = FALSE}
mu = coef(lm)[3]
se = sqrt(diag(vcov(lm)))[3]
pt(-abs((mu - 1)/se), lm$df)
```

We can reject the null hypothesis that the coefficient of age is equal to 1 at the 5% significance level against the one-sided alternative hypothesis that the coefficient is smaller than 1. We fail to reject the null hypothesis at the 1% significance level, though.

## (f)
```{r, message = FALSE}
2 * pt(-abs((mu - 1)/se), lm$df)
```

Against the two-sided alternative hypothesis, we fail to reject the null hypothesis at the 5% significance level.

## (g)
```{r, message = FALSE}
summary(lm(nettfa ~ inc, dataLM))
```

Running the model on only income, the coefficient of income increases slightly from 0.7993 to 0.8207. Both the intercept and the coefficient are statistically significant at the 1% significance level. This can be explained by the very slight positive correlation (0.0391) between age and income in the restricted sample. Age having a positive coefficient in the full model and the correlation between the two variables being positive, as well, implies a positive bias on the coefficient in the restricted model. Is is questionable, whether this difference is economically significant, though.
The adjusted R-squared decreases slightly, which is to be expected.

## (h)
```{r, message = FALSE}
lm = lm(nettfa ~ inc + age + incsq + agesq + fsize, data)
summary(lm)
```

In this model the intercept is not statistically significantly different from 0 at the 10% significance level. Family income is now statistically significant at the 10% significance level, but not at the 5% significance level. Age is statistically significant at the 5% significance level, but not at the 1% significance level. All new coefficients are statistically significant at the 1% significance level.
If all model variables are equal to 0 the model predicts net financial wealth of 13.9926, which seems more plausible than a negative value (though the intercept is statistically insignificant). Income and age now have negative values. This can be explained by the polynomial terms. There appear to be increasing marginal returns to both income and age. So the older or the more income an individual (or family household) has, the greater the incremental wealth for additional income and/or "additional age", on average, ceteris paribus. For income, for example, additional income starts to increase wealth starting at income of 2 * 0.0095 * x - 0.1266 = 0 <=> x = 6.6631 (6,6631 USD), on average, ceteris paribus. Finally, the coefficient of fsize is negative, -1.9792, meaning that financial wealth decreases with family size.
For every additional family member, net financial wealth decreases by 1,979 USD, on average, ceteris paribus. This could seem counterintuitive, since more family members could provide more labor and hence income, but large family size tends to correlate with poverty, in general. There are other factors and explanations, of course. Here, it would also be interesting to investigate potential increasing/decreasing marginal effects.
The adjusted R-squared also increases compared to model (1), though the sample changes, as well, making the comparison invalid.

## (i)
```{r, message = FALSE}
linearHypothesis(lm ,c("incsq = 0","agesq = 0"))
```

The null hypothesis of beta3 = beta4 = 0 can be rejected at the 1% significance level. This means that both variables add statistically significantly to the model by increasing the explained variance in the model. The SSR (sum of squared residuals) is significantly larger in the reduced model than in the full model. Nevertheless, it could still be that the variables are individually statistically insignificant and only work in conjunction.

## (j)
```{r, message = FALSE}
dataRE = data %>% mutate(inc = inc / 10, incsq = incsq / 100)
lm = lm(nettfa ~ inc + age + incsq + agesq + fsize, dataRE)
summary(lm)
```

The model stays the same, but the coefficient for income is now 10 times its previous size. The coefficient of incsq is scaled by 100 (10^2). Statistical significance stays unaffected, since the standard errors are scaled by the same factor for inc (x10) and incsq (x100), reversing the effect. The economic interpretation under consideration of the scaling also stays the same. The scaling has no material effect.

## (k)
```{r, message = FALSE}
bptest(nettfa ~ inc + age, data = dataLM, studentize = FALSE)
```

The null hypothesis of homoskedasticity can be rejected at the 1% significance level. The coefficients are jointly statistically significant and hence there still seems to be a relationship between the squared residuals and at least one variable. We thus found evidence for heteroskedasticity.

## (l)
```{r, message = FALSE}
lm = lm(nettfa ~ inc + age, dataLM)
coeftest(lm, vcov. = vcovHC(lm ,type = "HC0"))
```

Including robust standard errors does not change the estimates of the coefficients, but only increases the standard errors, for example from 0.0597 to 0.1007 for income. Thereby, the t-values become smaller, but the intercept and the coefficients are still statistically significant at the 1% significance level.

## (m)
```{r, message = FALSE}
zScore = function(x) {return((x-mean(x))/sd(x))}
lm = lm(zScore(nettfa) ~ zScore(inc) + zScore(age), dataLM)
summary(lm)
```

The intercept is effectively 0, as expected. The intercept is, of course, not statistically significantly different from 0, but the coefficients still are, at the 1% significance level. Both coefficients have become tremendously small. If income increases by 1 standard deviation, then net financial wealth increases by 0.2800 standard deviations, ceteris paribus. Similarly, if age increases by 1 standard deviation, net financial wealth increases by 0.1916 standard deviations, ceteris paribus. One unit is now a standard deviation.


# 3.

```{r, message = FALSE}
library(broom)
```

## (a)
```{r, message = FALSE}
path = paste0(getwd(), "/ceo_salary.dta")
data = read_dta(path)
data[c("college", "grad")] = lapply(data[c("college", "grad")], as.factor)

head(data)

lm = lm(lsalary ~ lsales + lmktval + ceoten + ceotensq, data)
summary(lm)
```

The intercept and all coefficients are statically significant at the 5% significance level. lsalary increases with lsales, lmktval, and ceoten, on average, ceteris paribus. The coefficient of ceotensq is negative, indicating decreasing marginal returns to ceoten.

## (b)
```{r, message = FALSE}
descriptiveStats = 
  describe(data[c("sales", "mktval", "lsales", "lmktval", "ceoten", "ceotensq")])
descriptiveStats
```

Taking the natural log can mitigate or eliminate problems arising from strictly positive variables that have heteroskedastic or skewed conditional distributions. Also, narrowing the range of the dependent and independent variables can make OLS estimates less sensitive to outliers. A common rules of thumb is that when a variable is a positive currency amount, take the log. 
That is also the case for lsales and lmktval, both of which are quoted in a currency. To compare, I have included also the variables without the log: sales and mktval. We can see that the variables without the logs exhibit strikingly larger skewness (4.14 vs -0.10 and 3.85 vs 0.84) and kurtosis (23.27 vs -0.21 and 17.84 vs -0.06) than the log variables. Thus, their distributions are becoming closer to a normal distribution, making them more viable for statistical inference. In addition, the original variables have larger means, larger standard deviations, and a larger range.

## (c)
```{r, message = FALSE}
coeftest(lm, vcov. = vcovHC(lm ,type = "HC0"))
```

The White standard errors are more conservative and thus larger than normal standard errors. Hence, the t-statistics are expected to decrease in absolute value for every coefficient and the intercept. Apparently, for the log variables, lsales and lmktval, that is not the case. Their standard errors decrease and the t-statistics increase for White standard errors.

## (d)
```{r, message = FALSE}
fullLM = augment(lm)
fullLM %>% dplyr::filter(abs(.std.resid) > 1.96) %>% count
nrow(data) * (2 * (1 - pnorm(2, 0, 1)))
```

There are 9 standardized residuals, whose absolute value is greater-equal to 1.96. If the standardized residuals were i.i.d draws from a standard normal distribution, we would expect about 8 our of 177 to be above 2 in absolute value. This can be considered slight evidence against normally distributed standardized residuals.

## (e)
```{r, message = FALSE}
lm = lm(lsalary ~ lsales + lmktval + ceoten + ceotensq + college + college:lsales, data)
summary(lm)
```

The intercept and all coefficients, but the one for lsales are statistically significant at the 5% significance level. According to the intercept, a CEO with no sales, leading a company with no market value, with no tenure, who didn't go to college earns exp(7.9443) = 2819.4580 in the respective currency, on average. The salary increases by 0.1180% when the market value increases by 1%, on average, ceteris paribus. Bigger companies pay higher salaries. As mentioned earlier, there are decreasing marginal effect to ceoten. We cannot tell the specific marginal effect, since it is non-constant. We can, however, mention the first derivative with respect to ceoten, which equals 0.0453 - 0.0024 * ceoten. This terms turns negative for ceoten >= 18.8750. It is questionable whether it makes economic sense that salary decreases marginally with tenure. 
Whether a ceo has gone to college has a differential flat impact on salary. The intercept for college goers becomes 7.9444 - 3.6619 = 4.2825, while it stays at 7.9444 for non-college-goers. Having gone to college decreases the salary 366.1882%, on average, ceteris paribus. This finding is surprising to me. Looking at the data more closely, however, I find that 172 of the 177 CEOs went to college. The mean lsalary among those CEOs is 6.5761, while it is 6.8134 among the non-college-goers. Thus, the sample is unbalanced in this regard, making the (external) validity of this finding questionable. 
Finally, the coefficient of the interaction term is positive. This means that the coefficient on lsales is -0.3000 + 0.4662 = 0.1662 for CEOs who went to college and still -0.3000 for non-college CEOs. For CEOs who went to college, a 1% increase in sales increases the salary by 0.1662%. For CEOs who didn't go to college, a 1% increase in sales decreases the salary by 0.3000%, though this coefficient is insignificant. Additionally, it would not make much sense that the salary decreases with sales.

## (f)
```{r, message = FALSE}
dataAD = data %>% mutate(lsales_adjusted = 0.9 * lsales)

lm = lm(lsalary ~ lsales_adjusted + lmktval + ceoten + ceotensq, dataAD)
summary(lm)
```

The new coefficient is 0.1829. Multiplying it by the scaling factor 0.9 returns the old coefficient, 0.1646. The standard error increases proportionally and the t-statistic, logically, stays the same. This is to be expected, since the scaling does nothing to the estimation precision. The other coefficients and statistics are unaffected, as well. This shows that when the measurement error is systematic (the bias is constant over all observations), one can correct for it with an appropriate scaling factor. The model now predicts a higher percentage change in salary as a response to a 1%-increase in sales. The precision stay the same, though.

## (g)
```{r, message = FALSE}
dataRE = fullLM %>% dplyr::filter(abs(.std.resid) < 1.96)

lm = lm(lsalary ~ lsales + lmktval + ceoten + ceotensq, dataRE)
summary(lm)
```

9 observations were dropped. ceotensq is now no longer statistically significant at the 5% significance level, while lmktval is now statistically significant at the 1% significance level. While the intercept and the coefficients show noticeable changes, the R-squared exhibits the most considerable change. The adjusted R-squared value increases from 0.3277 to 0.4920. Seemingly, the 9 dropped observations were outliers, since they deviated strongly from the regression line. As we can see, they had a negative effect on the model accuracy. It would be interesting to see what variable(s) made them outliers and whether they were truly outliers or just naturally extreme observations.


# 4.

```{r, message = FALSE}
library(plm)
library(lfe)
library(tseries)
```

## (a)
```{r, message = FALSE}
path = paste0(getwd(), "/local_returns.dta")
data = read_dta(path)
data[c("city", "ind", "date", "year", "permno")] = 
  lapply(data[c("city", "ind", "date", "year", "permno")], as.factor)
data = pdata.frame(data, c("permno", "date"))
head(data)

pdim(data)

# Balance among permnos
data %>% count(permno) %>% 
  summarize(min = min(n), max = max(n), sd = SD(n), shareMax = mean(n == max(n)))
n = data %>% count(permno) %>% select(n)
n = as.numeric(n[[1]])
hist(n, breaks = 132, main = paste("Distribution of the Observations per Individual Firm"), 
  xlab = "Number of Occurrences", ylab = "Count")

# Balance among date
data %>% count(date) %>% 
  summarize(min = min(n), max = max(n), sd = SD(n), shareMax = mean(n == max(n)))
n = data %>% count(date) %>% select(n)
n = as.numeric(n[[1]])
hist(n, breaks = 30, main = paste("Distribution of the Observations per Date"), 
  xlab = "Number of Occurrences", ylab = "Count")
data %>% count(year)

# Balance among cities
data %>% count(city) %>% summarize(min = min(n), max = max(n), sd = SD(n))
data %>% count(city)

# Balance among industries
data %>% count(ind) %>% summarize(min = min(n), max = max(n), sd = SD(n))
data %>% count(ind)
```

According to the bdim function from the plm package, the panel is unbalanced. 
To go a little further, we can look at two dispersion metrics, range and standard deviation, of the dimensions. First, looking at the distribution of the number of observations per individual firms, we see that the number differs widely from a minimum of 1 to a maximum of 132 with a standard deviation of 46.8766. Looking at the histogram, we see a mode at 132 observations; 25.5049% of the observations have this number of observations. On the whole, the panel looks far from balanced when it comes to the number of observations per individual firm.
The panel looks slightly more balanced when we look at the number of observations per date. Still, with a minimum of 3,073, a maximum of 4,642, and a standard deviation of 402, the data exhibits quite a degree of dispersion. In the histogram, we can also see that the count per date peaks at certain dates, serving as evidence against balance. We can also see that the number of observations per year decrease monotonously at an almost constant rate. This might be a sign of attrition, a phenomenon that occurs when you only observe a subset in subsequent periods. This leads to selection bias of unknown nature if the data is not missing at random and the selection is based on unobservables.
A similar picture emerges when we look at the balance across cities and industries. Imbalance here is to be expected though, since there are larger and smaller cities and industries.

## (b)
```{r, message = FALSE}
data %>% group_by(city) %>% summarize(mean = mean(ret), sd = SD(ret))
data %>% group_by(city) %>% summarize(mean = mean(ret), sd = SD(ret)) %>% 
  summarize(min(mean), max(mean), sd(mean))
data %>% group_by(city) %>% summarize(mean = mean(ret), sd = SD(ret)) %>% 
  summarize(min(sd), max(sd), sd(sd))
```

Among the 20 cities the average monthly firm returns differ widely. The minimum is 0.0059 in city 11 and the maximum is 0.0165 in city 8. The standard deviation of mean returns is quite considerable at 0.0028. The standard deviations also differ from a minimum of 0.1444 in city 3 to a maximum of 0.2401 in city 17 with a standard deviation of standard deviations of 0.0275. Strikingly, the minimum and maximum returns do not occur in the cities with the lowest and highest standard deviations, respectively. On a preliminary basis, this implies a violation of market efficiency (in terms of Sharpe ratio), though further investigations are needed.

## (c) & (d)
```{r, message = FALSE}
pooledLM = plm(ret ~ city_returns + indret, model = "pooling", data)
summary(pooledLM)
```

In the pooled regression, all coefficients and the intercept are statistically significant at the 1% significance level. According to this model, firm returns increase with city and industry returns, respectively, on average, ceteris paribus. There also seems to be a negative default return of -0.0015 that occurs, on average, for city and industry returns of 0.

## (e)
```{r, message = FALSE}
bptest(pooledLM, studentize = FALSE)
```

Here again, we apply the Breusch-Pagan test. The null hypothesis of homoskedasticity can be rejected at the 1% significance level. The coefficients are jointly statistically significant and hence there still seems to be a relationship between the squared residuals and at least one variable. We thus found evidence for heteroskedasticity.

## (f)
```{r, message = FALSE}
pooledLM_Date1 = felm(ret ~ city_returns + indret | date | 0 | 0, data)
summary(pooledLM_Date1)
```

Using pooled OLS with time fixed effects, the coefficients of city and industry returns stay statistically significant at the 1% significance level. The coefficient of city_returns decreases slight from 0.2122 to 0.1707 and the coefficient of indret increases slightly from 0.8558 to 0.8748. The standard errors of both coefficients increase slightly.

## (g)
```{r, message = FALSE}
pooledLM_Date_Firm = felm(ret ~ city_returns + indret | date + permno | 0 | 0, data)
summary(pooledLM_Date_Firm)
```

Compared to (f), the model changes barely. The coefficient on city_returns increases slightly and the coefficient on indret decreases slightly. The standard errors also increase slightly.

## (h)
```{r, message = FALSE}
pooledLM_Date_Firm_ad = felm(ret ~ city_returns + indret | date + permno | 0 | 
  date + permno, data)
summary(pooledLM_Date_Firm_ad)
```

Again, the coefficients barely change compared to (f) and (g). The standard errors, as expected, increase; Clustered standard errors are more conservative. The coefficients are still statistically significant at the 1% significance level. Among these models, the adjusted R-squared barely changes, as well.

## (i)
```{r, message = FALSE}
feLM_Date_Firm = plm(ret ~ city_returns + indret, model = "within", 
  index = c("permno", "date"), data)
summary(feLM_Date_Firm)
```

## (j) & (k)
```{r, message = FALSE}
fdLM_Date_Firm = plm(ret ~ city_returns + indret, model = "fd", 
  index = c("permno", "date"), data)
summary(fdLM_Date_Firm)
```

In terms of adjusted R-squared the pooled regression model in (h) has the highest value with 0.1557. The model in (i) has an adjusted R-squared of 0.1391 and the model in (j) 0.12359. In terms of coefficients, the models in (i) and (j) are similar. The coefficients for city_returns are slightly higher and for indret slightly lower than in (h). In all 3 models, both coefficients are statistically significant at the 1% significance level. Of these 3 models, the first difference model in (j) is the only one with an estimate for the intercept, -0.0002. This value is not statistically significant at the 10% significance level, though.

## (l)
```{r, message = FALSE}
adf.test(data$ret, k = 2)

dataRE = data %>% mutate(dummySF = ifelse(city == "10", 1, 0))
newLM = plm(ret ~ city_returns + indret + dummySF:city_returns, model = "within", 
  index = c("permno", "date"), dataRE)
summary(newLM)
```

Running the augmented Dickey-Fuller test on the outcome variable returns a p-value of less than 1%. This means that with reasonable confidence, no unit root is present and a fixed effect estimator is probably better here. This is also true considering that the panel is unbalanced.
According to the fixed effect model, the coefficient gamma is statistically significant at the 10% significance level, but not at the 5% significance level. The model can be interpreted as follows. For all cities but San Francisco, the firm returns increase by 0.2091 for an increase of 1 (100%) in the variable city_return and by 0.8540 for an increase of 1 in the variable indret, on average, ceteris paribus, respectively. We can see that both types of returns have a positive effect on the firm return, but the industry effect is stronger than the city effect (for all cities but San Francisco). For San Francisco, the same holds for the indret coefficient, but for city_returns, the effect is slightly stronger at 0.2331. An increase of 1 in the city_returns variable leads to a 0.2331 increase in the firm return, on average, ceteris paribus. 
This could imply that there are also city fixed effects that need to be accounted for.